{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1addaf3a-49cc-46c8-9794-59bfb26bd7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4c3f03-e8b3-48f2-ab95-9a767da6ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.stocks import read_and_concat_all_stocks\n",
    "from src.training.preparation import (\n",
    "    time_series_train_test_split,\n",
    "    separate_the_target_column,\n",
    "    prepare_nn_multistep_dataset\n",
    ")\n",
    "from src.training.feature_engineering import add_date_as_feature, add_lagged_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a202c5-93bb-46c9-a5de-5e626f7bf6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5a643a-8f2a-4fa4-9967-625a71d5db79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tickers': {'tickers_list_filename': 'sp500_tickers_list',\n",
       "  'tickers_list_save_path': './metadata/tickers_list/',\n",
       "  'tickers_wikipedia_url': 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies',\n",
       "  'exclude_tickers': ['GOOG']},\n",
       " 'stock': {'stock_data_start_date': '2010-01-01',\n",
       "  'stock_data_save_path': './data/raw_stocks/'},\n",
       " 'configs': {'train_config': './configs/train/train_cfg.yaml'},\n",
       " 'train_config': {'target': {'target_column': 'AAPL', 'prediction_window': 7},\n",
       "  'train_test_split': {'validation_size': 30},\n",
       "  'feature_engineering': {'n_lags': 1}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80090d31-d160-4e0d-8bb8-15beb911aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae909db-468b-42d6-99d6-0d2ecc00c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../configs/main.yaml\", \"r\") as f:\n",
    "                temp_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38aa0bb3-366a-4c5a-b881-4cf91f58aef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_config_path': './configs/train/train_cfg.yaml'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_config['configs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4175b6ef-5a16-4c11-9dc7-34894750a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data/\"\n",
    "data_folder_path = Path(data_folder)\n",
    "\n",
    "target_stocks = [\n",
    "    \"AAPL\",\n",
    "    \"GOOGL\",\n",
    "    \"AMZN\",\n",
    "    \"TSLA\",\n",
    "    \"NVDA\",\n",
    "    \"MSFT\",\n",
    "    \"META\"\n",
    "]\n",
    "\n",
    "target_column = \"AAPL\"\n",
    "n_lags = 10\n",
    "output_size = 5\n",
    "validation_size = 30\n",
    "hidden_dim = 256\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22a12c8-9d12-4825-a7e0-acf9812e954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.preparation import prepare_data_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afd5042-e716-48df-8c0c-c1d68db6bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = prepare_data_for_training(data_folder_path, target_column, n_lags=1, validation_size=30, prediction_window=7, save_path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7cdfd0c-cad1-4c09-885d-cb998b5c82c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3883, 426]),\n",
       " torch.Size([3883, 7]),\n",
       " torch.Size([30, 426]),\n",
       " torch.Size([30, 7]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d30a1160-70e7-483b-9d6e-195627b3fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input size\n",
    "input_size = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95fc43f2-3dce-4453-96ac-0d99db159856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.models import FeedforwardRegressor\n",
    "from src.training.loss_functions import masked_mse_loss\n",
    "from src.training.trainers import trainer\n",
    "from src.utils.checks import check_datatypes\n",
    "from src.utils.path import verify_saving_path, verify_existing_dir\n",
    "from src.training.utils import validate_device\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36336e6d-c28e-4b05-959c-18d5b1448540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc358f99-0b46-41b8-aea6-bc02ed9df8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_processed_stock_data(data_folder):\n",
    "    \"\"\"\n",
    "    Find the most recent dated subfolder in the given data folder,\n",
    "    then load and return the PyTorch tensors stored in the files:\n",
    "    'X_train.pt', 'X_valid.pt', 'y_train.pt', and 'y_valid.pt'.\n",
    "\n",
    "    Assumes that the subfolder names are dates in the format 'YYYY-MM-DD'\n",
    "    and that each subfolder contains the above four files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_folder : str or Path\n",
    "        Path to the main data folder containing date-named subfolders.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of torch.Tensor\n",
    "        Returns a tuple with four tensors in this order:\n",
    "        (X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If the data_folder does not exist, is not a directory,\n",
    "        or if any of the expected .pt files are missing.\n",
    "    ValueError\n",
    "        If no valid date-named subfolders are found or folder names do not match the date format.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "\n",
    "    # Convert input to Path object if needed\n",
    "    data_folder = Path(data_folder)\n",
    "\n",
    "    # Verify that the directory exists\n",
    "    verify_existing_dir(data_folder)\n",
    "\n",
    "    # List all subfolders inside data_folder\n",
    "    subfolders = data_folder.glob(\"*\")\n",
    "\n",
    "    # Get the most recent folder by date-parsing folder names\n",
    "    most_recent_folder = max(\n",
    "        subfolders,\n",
    "        key=lambda f: datetime.strptime(f.name, \"%Y-%m-%d\")\n",
    "    )\n",
    "\n",
    "    # Define expected files inside the most recent folder\n",
    "    expected_files = [\"X_train.pt\", \"X_valid.pt\", \"y_train.pt\", \"y_valid.pt\"]\n",
    "\n",
    "    # Build full paths and check if all files exist\n",
    "    file_paths = {}\n",
    "    for fname in expected_files:\n",
    "        fpath = most_recent_folder / fname\n",
    "        if not fpath.is_file():\n",
    "            raise FileNotFoundError(f\"Expected file not found: {fpath}\")\n",
    "        file_paths[fname] = fpath\n",
    "\n",
    "    # Load the tensors using torch.load\n",
    "    X_train = torch.load(file_paths[\"X_train.pt\"])\n",
    "    X_valid = torch.load(file_paths[\"X_valid.pt\"])\n",
    "    y_train = torch.load(file_paths[\"y_train.pt\"])\n",
    "    y_valid = torch.load(file_paths[\"y_valid.pt\"])\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4e531fd-3a72-43bb-b8b4-d354b4858948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.training.loss_functions as loss_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03a1dfdf-6953-4e6c-aaaa-71bf9638eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = getattr(loss_functions, \"masked_mse_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58c08663-954f-4c9d-8859-b8585bd28ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function src.training.loss_functions.masked_mse_loss(preds, targets)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17d6cc44-b6cb-41d7-bccc-7cf322660941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.9932e+01, 6.4319e+00, 1.8497e+01,  ..., 2.0100e+03, 1.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.9715e+01, 6.4430e+00, 1.8347e+01,  ..., 2.0100e+03, 1.0000e+00,\n",
       "          1.0000e+00],\n",
       "         [1.9645e+01, 6.3405e+00, 1.8449e+01,  ..., 2.0100e+03, 1.0000e+00,\n",
       "          2.0000e+00],\n",
       "         ...,\n",
       "         [1.2027e+02, 2.0267e+02, 1.3353e+02,  ..., 2.0250e+03, 6.0000e+00,\n",
       "          1.0000e+00],\n",
       "         [1.1947e+02, 1.9878e+02, 1.3468e+02,  ..., 2.0250e+03, 6.0000e+00,\n",
       "          2.0000e+00],\n",
       "         [1.1866e+02, 1.9920e+02, 1.3584e+02,  ..., 2.0250e+03, 6.0000e+00,\n",
       "          3.0000e+00]]),\n",
       " tensor([[1.1683e+02, 1.9645e+02, 1.3501e+02,  ..., 2.0250e+03, 6.0000e+00,\n",
       "          4.0000e+00],\n",
       "         [1.1877e+02, 1.9842e+02, 1.3341e+02,  ..., 2.0250e+03, 6.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.1585e+02, 1.9564e+02, 1.3169e+02,  ..., 2.0250e+03, 6.0000e+00,\n",
       "          1.0000e+00],\n",
       "         ...,\n",
       "         [1.2035e+02, 2.1376e+02, 1.2564e+02,  ..., 2.0250e+03, 7.0000e+00,\n",
       "          3.0000e+00],\n",
       "         [1.2018e+02, 2.1388e+02, 1.2654e+02,  ..., 2.0250e+03, 7.0000e+00,\n",
       "          4.0000e+00],\n",
       "         [1.1954e+02, 2.1405e+02, 1.2635e+02,  ..., 2.0250e+03, 7.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " tensor([[  6.4430,   6.3405,   6.3288,  ...,   6.3147,   6.2429,   6.3309],\n",
       "         [  6.3405,   6.3288,   6.3709,  ...,   6.2429,   6.3309,   6.2942],\n",
       "         [  6.3288,   6.3709,   6.3147,  ...,   6.3309,   6.2942,   6.1891],\n",
       "         ...,\n",
       "         [198.7800, 199.2000, 196.4500,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [199.2000, 196.4500,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [196.4500,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]),\n",
       " tensor([[198.4200, 195.6400, 196.5800, 201.0000, 201.5000, 200.3000, 201.5600],\n",
       "         [195.6400, 196.5800, 201.0000, 201.5000, 200.3000, 201.5600, 201.0000],\n",
       "         [196.5800, 201.0000, 201.5000, 200.3000, 201.5600, 201.0000, 201.0800],\n",
       "         [201.0000, 201.5000, 200.3000, 201.5600, 201.0000, 201.0800, 205.1700],\n",
       "         [201.5000, 200.3000, 201.5600, 201.0000, 201.0800, 205.1700, 207.8200],\n",
       "         [200.3000, 201.5600, 201.0000, 201.0800, 205.1700, 207.8200, 212.4400],\n",
       "         [201.5600, 201.0000, 201.0800, 205.1700, 207.8200, 212.4400, 213.5500],\n",
       "         [201.0000, 201.0800, 205.1700, 207.8200, 212.4400, 213.5500, 209.9500],\n",
       "         [201.0800, 205.1700, 207.8200, 212.4400, 213.5500, 209.9500, 210.0100],\n",
       "         [205.1700, 207.8200, 212.4400, 213.5500, 209.9500, 210.0100, 211.1400],\n",
       "         [207.8200, 212.4400, 213.5500, 209.9500, 210.0100, 211.1400, 212.4100],\n",
       "         [212.4400, 213.5500, 209.9500, 210.0100, 211.1400, 212.4100, 211.1600],\n",
       "         [213.5500, 209.9500, 210.0100, 211.1400, 212.4100, 211.1600, 208.6200],\n",
       "         [209.9500, 210.0100, 211.1400, 212.4100, 211.1600, 208.6200, 209.1100],\n",
       "         [210.0100, 211.1400, 212.4100, 211.1600, 208.6200, 209.1100, 210.1600],\n",
       "         [211.1400, 212.4100, 211.1600, 208.6200, 209.1100, 210.1600, 210.0200],\n",
       "         [212.4100, 211.1600, 208.6200, 209.1100, 210.1600, 210.0200, 211.1800],\n",
       "         [211.1600, 208.6200, 209.1100, 210.1600, 210.0200, 211.1800, 212.4800],\n",
       "         [208.6200, 209.1100, 210.1600, 210.0200, 211.1800, 212.4800, 214.4000],\n",
       "         [209.1100, 210.1600, 210.0200, 211.1800, 212.4800, 214.4000, 214.1500],\n",
       "         [210.1600, 210.0200, 211.1800, 212.4800, 214.4000, 214.1500, 213.7600],\n",
       "         [210.0200, 211.1800, 212.4800, 214.4000, 214.1500, 213.7600, 213.8800],\n",
       "         [211.1800, 212.4800, 214.4000, 214.1500, 213.7600, 213.8800, 214.0500],\n",
       "         [212.4800, 214.4000, 214.1500, 213.7600, 213.8800, 214.0500, 211.2700],\n",
       "         [214.4000, 214.1500, 213.7600, 213.8800, 214.0500, 211.2700,   0.0000],\n",
       "         [214.1500, 213.7600, 213.8800, 214.0500, 211.2700,   0.0000,   0.0000],\n",
       "         [213.7600, 213.8800, 214.0500, 211.2700,   0.0000,   0.0000,   0.0000],\n",
       "         [213.8800, 214.0500, 211.2700,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "         [214.0500, 211.2700,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "         [211.2700,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_processed_stock_data(\"../data/processed_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a51b951-3ba7-4e7f-af5e-1a787ff3cf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FeedforwardRegressor'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeedforwardRegressor.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "100fccf5-c36c-4da8-9fd0-fcd827f21e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.123"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(113.123241, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8b5f7ad-2570-4b26-ae03-ad39c1008552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_architecture,\n",
    "                X_train,\n",
    "                y_train,\n",
    "                X_valid,\n",
    "                y_valid,\n",
    "                loss_fn,\n",
    "                prediction_window=7,\n",
    "                batch_size=32,\n",
    "                n_epochs=100,\n",
    "                learning_rate=0.001,\n",
    "                shuffle=True,\n",
    "                model_params=None,\n",
    "                device='cpu',\n",
    "                save_path=\"./\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Train a PyTorch model using the provided architecture and datasets, then save the traced model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_architecture : type\n",
    "        A PyTorch module class (not instance) representing the model architecture. It must accept `input_dim` and \n",
    "        `output_dim` as keyword arguments in addition to any custom `model_params`.\n",
    "    \n",
    "    X_train : torch.Tensor\n",
    "        Training input features of shape (n_samples, n_features).\n",
    "    \n",
    "    y_train : torch.Tensor\n",
    "        Training target values of shape (n_samples, prediction_window).\n",
    "    \n",
    "    X_valid : torch.Tensor\n",
    "        Validation input features of shape (n_samples, n_features).\n",
    "    \n",
    "    y_valid : torch.Tensor\n",
    "        Validation target values of shape (n_samples, prediction_window).\n",
    "    \n",
    "    loss_fn : callable\n",
    "        Loss function used during training. Must accept predicted and true outputs as inputs.\n",
    "    \n",
    "    prediction_window : int, optional\n",
    "        Number of future steps to predict, by default 7.\n",
    "    \n",
    "    batch_size : int, optional\n",
    "        Number of samples per training batch, by default 32.\n",
    "    \n",
    "    n_epochs : int, optional\n",
    "        Number of epochs to train for, by default 100.\n",
    "    \n",
    "    learning_rate : float, optional\n",
    "        Learning rate for the optimizer, by default 0.001.\n",
    "    \n",
    "    shuffle : bool, optional\n",
    "        Whether to shuffle the training data during batching, by default True.\n",
    "    \n",
    "    model_params : dict or None, optional\n",
    "        Additional keyword arguments to pass to the model constructor, by default None.\n",
    "    \n",
    "    device : str, optional\n",
    "        Device on which to train the model (e.g., 'cpu' or 'cuda'), by default 'cpu'.\n",
    "    \n",
    "    save_path : str or pathlib.Path, optional\n",
    "        Directory path where the traced model will be saved, by default \"./\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : torch.nn.Module\n",
    "        The trained PyTorch model instance.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data_types_schema = [\n",
    "        (\"model_architecture\", model_architecture, nn.Module),\n",
    "        (\"X_train\", X_train, torch.Tensor),\n",
    "        (\"y_train\", y_train, torch.Tensor),\n",
    "        (\"X_valid\", X_valid, torch.Tensor),\n",
    "        (\"y_valid\", y_valid, torch.Tensor),\n",
    "        (\"loss_fn\", loss_fn),\n",
    "        (\"prediction_window\", prediction_window, int),\n",
    "        (\"batch_size\", batch_size, int),\n",
    "        (\"n_epochs\", n_epochs, int),\n",
    "        (\"learning_rate\", learning_rate, float),\n",
    "        (\"shuffle\", shuffle, bool),\n",
    "        (\"model_params\", model_params, dict),\n",
    "        (\"device\", device, str),\n",
    "        (\"save_path\", save_path, (str, Path))\n",
    "    ]\n",
    "\n",
    "    # Check if all data types provided are correct\n",
    "    check_datatypes(data_types_schema)\n",
    "\n",
    "    # Check if the provided saving path is correctly provided\n",
    "    save_path = Path(save_path)\n",
    "    verify_saving_path(save_path)\n",
    "\n",
    "    # Get todays date\n",
    "    todays_date = datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "    # Model params is an empty dictionary if None is provided\n",
    "    model_params = {} if model_params is None else model_params\n",
    "\n",
    "    # Get the input size\n",
    "    input_size = X_train.shape[1]\n",
    "\n",
    "    # Wrap training data into a DataLoader\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    # Define the model\n",
    "    model = model_architecture(input_dim=input_size,\n",
    "                               output_dim=prediction_window,\n",
    "                               **model_params).to(device)\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    model, val_loss = trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        X_valid=X_valid,\n",
    "        y_valid=y_valid,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=masked_mse_loss,\n",
    "        n_epochs=n_epochs,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Note that it's assumed that input is 1D here\n",
    "    example_input = torch.randn(1, input_size)\n",
    "\n",
    "    # Produce the computational graph\n",
    "    traced_model = torch.jit.trace(model.cpu(), example_input)\n",
    "\n",
    "    # Save the model\n",
    "    traced_model.save(save_path / f\"{model_architecture.__name__}_{todays_date}_{val_loss}.pt\")\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a663f02e-2f76-4f50-8f47-93fd1878ee07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Train Loss: 240.8914 - Val Loss: 36.1221\n",
      "Epoch 2/100 - Train Loss: 96.0538 - Val Loss: 129.5992\n",
      "Epoch 3/100 - Train Loss: 54.8940 - Val Loss: 46.0809\n",
      "Epoch 4/100 - Train Loss: 49.1767 - Val Loss: 539.7546\n",
      "Epoch 5/100 - Train Loss: 53.0057 - Val Loss: 240.5298\n",
      "Epoch 6/100 - Train Loss: 38.7454 - Val Loss: 47.2514\n",
      "Epoch 7/100 - Train Loss: 38.1695 - Val Loss: 148.9607\n",
      "Epoch 8/100 - Train Loss: 33.9217 - Val Loss: 166.2247\n",
      "Epoch 9/100 - Train Loss: 27.7492 - Val Loss: 397.8635\n",
      "Epoch 10/100 - Train Loss: 35.4550 - Val Loss: 28.9498\n",
      "Epoch 11/100 - Train Loss: 26.3158 - Val Loss: 154.5502\n",
      "Epoch 12/100 - Train Loss: 35.2254 - Val Loss: 29.7353\n",
      "Epoch 13/100 - Train Loss: 22.8817 - Val Loss: 35.8374\n",
      "Epoch 14/100 - Train Loss: 18.9910 - Val Loss: 25.6086\n",
      "Epoch 15/100 - Train Loss: 19.7127 - Val Loss: 56.0552\n",
      "Epoch 16/100 - Train Loss: 34.5863 - Val Loss: 120.6449\n",
      "Epoch 17/100 - Train Loss: 19.1132 - Val Loss: 29.1526\n",
      "Epoch 18/100 - Train Loss: 30.0356 - Val Loss: 62.8390\n",
      "Epoch 19/100 - Train Loss: 36.3742 - Val Loss: 30.3732\n",
      "Epoch 20/100 - Train Loss: 20.0996 - Val Loss: 56.9756\n",
      "Epoch 21/100 - Train Loss: 17.8714 - Val Loss: 49.5780\n",
      "Epoch 22/100 - Train Loss: 20.8788 - Val Loss: 28.0239\n",
      "Epoch 23/100 - Train Loss: 17.7808 - Val Loss: 84.7281\n",
      "Epoch 24/100 - Train Loss: 19.0430 - Val Loss: 54.9922\n",
      "Epoch 25/100 - Train Loss: 25.9986 - Val Loss: 28.0450\n",
      "Epoch 26/100 - Train Loss: 20.3524 - Val Loss: 30.5385\n",
      "Epoch 27/100 - Train Loss: 27.4308 - Val Loss: 128.0786\n",
      "Epoch 28/100 - Train Loss: 20.5082 - Val Loss: 41.4925\n",
      "Epoch 29/100 - Train Loss: 17.9492 - Val Loss: 251.2155\n",
      "Epoch 30/100 - Train Loss: 18.7295 - Val Loss: 38.0405\n",
      "Epoch 31/100 - Train Loss: 21.7199 - Val Loss: 73.5425\n",
      "Epoch 32/100 - Train Loss: 21.5571 - Val Loss: 21.9668\n",
      "Epoch 33/100 - Train Loss: 23.1290 - Val Loss: 43.2991\n",
      "Epoch 34/100 - Train Loss: 19.1137 - Val Loss: 23.7490\n",
      "Epoch 35/100 - Train Loss: 15.3991 - Val Loss: 25.0990\n",
      "Epoch 36/100 - Train Loss: 15.9941 - Val Loss: 41.0689\n",
      "Epoch 37/100 - Train Loss: 29.1901 - Val Loss: 22.7382\n",
      "Epoch 38/100 - Train Loss: 14.2774 - Val Loss: 107.5160\n",
      "Epoch 39/100 - Train Loss: 16.2306 - Val Loss: 24.0379\n",
      "Epoch 40/100 - Train Loss: 15.9526 - Val Loss: 23.7886\n",
      "Epoch 41/100 - Train Loss: 18.6656 - Val Loss: 25.6450\n",
      "Epoch 42/100 - Train Loss: 16.4372 - Val Loss: 189.2478\n",
      "Epoch 43/100 - Train Loss: 18.1534 - Val Loss: 24.0522\n",
      "Epoch 44/100 - Train Loss: 19.5112 - Val Loss: 30.1863\n",
      "Epoch 45/100 - Train Loss: 12.6018 - Val Loss: 26.2214\n",
      "Epoch 46/100 - Train Loss: 15.5329 - Val Loss: 28.5276\n",
      "Epoch 47/100 - Train Loss: 14.2545 - Val Loss: 51.8472\n",
      "Epoch 48/100 - Train Loss: 16.3077 - Val Loss: 196.8835\n",
      "Epoch 49/100 - Train Loss: 16.4251 - Val Loss: 24.9985\n",
      "Epoch 50/100 - Train Loss: 15.2871 - Val Loss: 45.1146\n",
      "Epoch 51/100 - Train Loss: 26.6966 - Val Loss: 40.2414\n",
      "Epoch 52/100 - Train Loss: 14.3177 - Val Loss: 53.7601\n",
      "Epoch 53/100 - Train Loss: 16.6794 - Val Loss: 23.5317\n",
      "Epoch 54/100 - Train Loss: 13.2651 - Val Loss: 213.9712\n",
      "Epoch 55/100 - Train Loss: 24.2672 - Val Loss: 28.2027\n",
      "Epoch 56/100 - Train Loss: 13.9727 - Val Loss: 24.3569\n",
      "Epoch 57/100 - Train Loss: 12.3152 - Val Loss: 24.0175\n",
      "Epoch 58/100 - Train Loss: 21.0694 - Val Loss: 23.4386\n",
      "Epoch 59/100 - Train Loss: 14.0079 - Val Loss: 24.9055\n",
      "Epoch 60/100 - Train Loss: 13.4189 - Val Loss: 36.0861\n",
      "Epoch 61/100 - Train Loss: 13.2525 - Val Loss: 46.5169\n",
      "Epoch 62/100 - Train Loss: 14.8698 - Val Loss: 51.8601\n",
      "Epoch 63/100 - Train Loss: 15.8728 - Val Loss: 34.0206\n",
      "Epoch 64/100 - Train Loss: 13.0992 - Val Loss: 23.1871\n",
      "Epoch 65/100 - Train Loss: 12.6218 - Val Loss: 54.0678\n",
      "Epoch 66/100 - Train Loss: 13.6243 - Val Loss: 22.3672\n",
      "Epoch 67/100 - Train Loss: 16.1151 - Val Loss: 40.1561\n",
      "Epoch 68/100 - Train Loss: 15.1392 - Val Loss: 21.9694\n",
      "Epoch 69/100 - Train Loss: 17.9751 - Val Loss: 26.3203\n",
      "Epoch 70/100 - Train Loss: 12.8403 - Val Loss: 21.2863\n",
      "Epoch 71/100 - Train Loss: 13.8170 - Val Loss: 41.2052\n",
      "Epoch 72/100 - Train Loss: 15.8903 - Val Loss: 30.0320\n",
      "Epoch 73/100 - Train Loss: 12.4965 - Val Loss: 55.7522\n",
      "Epoch 74/100 - Train Loss: 12.4160 - Val Loss: 78.8719\n",
      "Epoch 75/100 - Train Loss: 12.9343 - Val Loss: 59.3671\n",
      "Epoch 76/100 - Train Loss: 15.7497 - Val Loss: 74.1174\n",
      "Epoch 77/100 - Train Loss: 18.7745 - Val Loss: 29.2994\n",
      "Epoch 78/100 - Train Loss: 11.7382 - Val Loss: 25.7686\n",
      "Epoch 79/100 - Train Loss: 12.1961 - Val Loss: 54.8117\n",
      "Epoch 80/100 - Train Loss: 14.1394 - Val Loss: 42.2375\n",
      "Epoch 81/100 - Train Loss: 15.5059 - Val Loss: 37.6396\n",
      "Epoch 82/100 - Train Loss: 14.4643 - Val Loss: 23.2145\n",
      "Epoch 83/100 - Train Loss: 15.5222 - Val Loss: 25.5290\n",
      "Epoch 84/100 - Train Loss: 11.4740 - Val Loss: 21.9952\n",
      "Epoch 85/100 - Train Loss: 12.6311 - Val Loss: 21.2088\n",
      "Epoch 86/100 - Train Loss: 11.0532 - Val Loss: 37.7243\n",
      "Epoch 87/100 - Train Loss: 10.9284 - Val Loss: 23.4223\n",
      "Epoch 88/100 - Train Loss: 18.2886 - Val Loss: 28.0073\n",
      "Epoch 89/100 - Train Loss: 10.6795 - Val Loss: 33.1845\n",
      "Epoch 90/100 - Train Loss: 12.5911 - Val Loss: 25.6344\n",
      "Epoch 91/100 - Train Loss: 11.9246 - Val Loss: 45.0406\n",
      "Epoch 92/100 - Train Loss: 15.0681 - Val Loss: 21.0104\n",
      "Epoch 93/100 - Train Loss: 13.4329 - Val Loss: 50.0651\n",
      "Epoch 94/100 - Train Loss: 13.9433 - Val Loss: 30.4201\n",
      "Epoch 95/100 - Train Loss: 11.8228 - Val Loss: 28.2127\n",
      "Epoch 96/100 - Train Loss: 13.4113 - Val Loss: 22.9459\n",
      "Epoch 97/100 - Train Loss: 13.7534 - Val Loss: 25.3762\n",
      "Epoch 98/100 - Train Loss: 13.1417 - Val Loss: 21.5796\n",
      "Epoch 99/100 - Train Loss: 12.1138 - Val Loss: 112.2841\n",
      "Epoch 100/100 - Train Loss: 12.2763 - Val Loss: 24.9011\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(\n",
    "    FeedforwardRegressor,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    masked_mse_loss,\n",
    "    prediction_window=7,\n",
    "    batch_size=32,\n",
    "    n_epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    shuffle=True,\n",
    "    model_params={\"hidden_dim\":512},\n",
    "    device='cuda',\n",
    "    save_path=\"./\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc0b285-dd43-4655-bfde-aaf4f83c3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88a81afb-3e0f-43d5-a864-a26e89dbf9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95443cba-242a-47cb-87ef-b7bdc6029e14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1. Move model and data to appropriate device\u001b[39;00m\n\u001b[32m      2\u001b[39m model.eval()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_train_cpu = X_train.to(\u001b[43mdevice\u001b[49m)\n\u001b[32m      4\u001b[39m y_train_cpu = y_train.to(device)\n\u001b[32m      5\u001b[39m X_valid_cpu = X_valid.to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Move model and data to appropriate device\n",
    "model.eval()\n",
    "X_train_cpu = X_train.to(device)\n",
    "y_train_cpu = y_train.to(device)\n",
    "X_valid_cpu = X_valid.to(device)\n",
    "y_valid_cpu = y_valid.to(device)\n",
    "\n",
    "# 2. Predict outputs\n",
    "with torch.no_grad():\n",
    "    y_train_pred = model(X_train_cpu)\n",
    "    y_valid_pred = model(X_valid_cpu)\n",
    "\n",
    "# 3. Convert to numpy\n",
    "y_train_true = y_train_cpu.cpu().numpy()\n",
    "y_train_pred = y_train_pred.cpu().numpy()\n",
    "y_valid_true = y_valid_cpu.cpu().numpy()\n",
    "y_valid_pred = y_valid_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d6460d2-45bd-4a51-8b9a-88f1a6ca1842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3874, 5), (3874, 5), (30, 5), (30, 5))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_true.shape, y_train_pred.shape, y_valid_true.shape, y_valid_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37edb4e3-ba0a-4567-b383-1ef998e2feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_predictions_per_timestamp(y_pred):\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    n_windows, window = y_pred.shape\n",
    "    \n",
    "\n",
    "    # Store predictions as lists per timestamp\n",
    "    all_preds = [[] for _ in range(n_windows)]\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        for j in range(window):\n",
    "            t = i + j\n",
    "            if t < n_windows and y_pred[i, j] != 0:\n",
    "                all_preds[t].append(y_pred[i, j])\n",
    "\n",
    "    # Pad to length 7 (or fill with NaNs) for consistency\n",
    "    padded_preds = np.full((n_windows, output_size), np.nan)\n",
    "    for t, preds in enumerate(all_preds):\n",
    "        padded_preds[t, :len(preds)] = preds\n",
    "\n",
    "    return padded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f116a271-2bf1-4c69-b5be-6b7453b14e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_valid_with_preds(y_train,\n",
    "                                y_train_pred,\n",
    "                                y_valid,\n",
    "                                y_valid_pred,\n",
    "                                title=\"Train and Validation Sets Plot With Predictions\",\n",
    "                                x_label=\"Timestamp\",\n",
    "                                y_label=\"Value\",\n",
    "                                figsize=(12, 5),\n",
    "                                zoom_out=1\n",
    "                                ):\n",
    "                                \n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Train and it's target\n",
    "    train_size = len(y_train)\n",
    "    plt.plot(range(train_size), y_train, label=\"Train Target\", color=\"tab:blue\")\n",
    "\n",
    "    train_predicted_avg = collect_predictions_per_timestamp(y_train_pred)\n",
    "    plt.plot(range(train_size), np.nanmean(train_predicted_avg, axis=1), label=\"Train Predicted\", color=\"tab:orange\")\n",
    "\n",
    "    # Validation and it's target\n",
    "    valid_size = len(y_valid)\n",
    "    valid_start = train_size + 1\n",
    "    valid_end = train_size + len(y_valid) + 1 \n",
    "    plt.plot(range(valid_start, valid_end), y_valid, label=\"Validation Target\", color=\"tab:blue\")\n",
    "\n",
    "    valid_predicted = collect_predictions_per_timestamp(y_valid_pred)\n",
    "    plt.plot(range(valid_start, valid_end), np.nanmean(valid_predicted, axis=1), label=\"Validation Predicted\", color=\"brown\")\n",
    "    plt.plot(range(valid_start, valid_end), valid_predicted, color=\"gray\", alpha=0.3)\n",
    "\n",
    "    plt.axvline(x=train_size, color='gray', linestyle='--', label='Change to validation set')\n",
    "\n",
    "    validation_y = y_valid.mean()\n",
    "    validation_x = (train_size + valid_end) // 2\n",
    "    figsize_x_over_y = figsize[0] / figsize[1]\n",
    "\n",
    "    plt.xlim(validation_x-zoom_out*valid_size*figsize_x_over_y, validation_x+zoom_out*valid_size*figsize_x_over_y)\n",
    "    plt.ylim(validation_y-zoom_out*valid_size, validation_y+zoom_out*valid_size)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462d7b9d-d501-46a8-842f-510105676833",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_train_valid_with_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_train_valid_with_preds\u001b[49m(y_train_raw,\n\u001b[1;32m      2\u001b[0m                             y_train_pred,\n\u001b[1;32m      3\u001b[0m                             y_valid_raw,\n\u001b[1;32m      4\u001b[0m                             y_valid_pred,\n\u001b[1;32m      5\u001b[0m                             zoom_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m                             )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_train_valid_with_preds' is not defined"
     ]
    }
   ],
   "source": [
    "plot_train_valid_with_preds(y_train_raw,\n",
    "                            y_train_pred,\n",
    "                            y_valid_raw,\n",
    "                            y_valid_pred,\n",
    "                            zoom_out=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8da8c-9013-4be9-aff3-b44eceef6e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57802400-9339-4437-8200-4886ec5c89eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

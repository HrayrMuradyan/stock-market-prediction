{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf34a79a-33eb-44df-b756-cd6cf89d723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from src.data.stocks import read_processed_data\n",
    "from src.utils.checks import check_datatypes\n",
    "from src.evaluation.plots import plot_train_valid_with_preds\n",
    "\n",
    "from src.evaluation.plots import (\n",
    "    plot_interactive_predictions_with_slider,\n",
    "    plot_error,\n",
    "    plot_directional_accuracy_heatmap\n",
    ")\n",
    "\n",
    "from src.evaluation.utils import collect_predictions_per_timestamp\n",
    "from src.evaluation.metrics import (\n",
    "    calc_mse,\n",
    "    calc_mae,\n",
    "    calc_rmse,\n",
    "    calc_mape,\n",
    "    calc_directional_accuracy\n",
    ")\n",
    "\n",
    "from src.utils.config import load_config\n",
    "from src.utils.path import get_project_root_path, verify_existing_dir, verify_saving_path, verify_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6f596c-c786-4d0b-9620-96ab9c0d6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "179536c0-8518-4990-9bae-7cd84bd2413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_results():\n",
    "\n",
    "    # Load the config\n",
    "    config = load_config()\n",
    "\n",
    "    # Get the model train results path\n",
    "    # If there is a specific model provided in the eval_config, take that. If not, take the most recent train folder\n",
    "    config_model_train_results_path = config['eval_config']['general']['model_train_results_path']\n",
    "\n",
    "    # CHANGE HERE\n",
    "    if not config_model_train_results_path:\n",
    "        model_train_results_path = [p for p in Path(\".\" + config['train_config']['model']['save_path']).iterdir() if p.is_dir()][-1]\n",
    "    else:\n",
    "        model_train_results_path = config_model_train_results_path\n",
    "        verify_existing_dir(model_train_results_path)\n",
    "\n",
    "    # Get the save path for the results from the config\n",
    "    results_save_path = config['eval_config']['general']['results_save_path']\n",
    "    results_save_path = Path(results_save_path) / model_train_results_path.stem\n",
    "\n",
    "    # Get the valid stock folders\n",
    "    stock_folders = [stock_folder for stock_folder in Path(model_train_results_path).iterdir() if stock_folder.is_dir()]\n",
    "\n",
    "    # For each folder\n",
    "    for stock_folder in stock_folders:\n",
    "\n",
    "        # Get the ticker name\n",
    "        ticker = stock_folder.stem \n",
    "\n",
    "        # Verify the existence of the save path\n",
    "        results_save_path_ticker = results_save_path / ticker\n",
    "        verify_saving_path(results_save_path_ticker)\n",
    "\n",
    "        # Get the most recent model file\n",
    "        model_folder = next(stock_folder.glob(\"model_*.pt\"))\n",
    "        \n",
    "        # Read the hyperparameters used for the training\n",
    "        with open(stock_folder / \"hyperparams.json\", \"r\") as f:\n",
    "            hyperparams = json.load(f)\n",
    "        \n",
    "        # Load the predictions dictionary for both train and validation sets\n",
    "        predictions_dict = torch.load(stock_folder / \"predictions_list.pt\")\n",
    "\n",
    "        # Get the last predictions from the predictions dict\n",
    "        y_train_pred_window = predictions_dict[\"train_preds_list\"][-1]\n",
    "        y_valid_pred_window = predictions_dict[\"valid_preds_list\"][-1]\n",
    "\n",
    "        # Get the average for each time stamp\n",
    "        y_train_pred_window_per_timestamp = collect_predictions_per_timestamp(y_train_pred_window)    # np.array (n, prediction_window)\n",
    "        y_valid_pred_window_per_timestamp = collect_predictions_per_timestamp(y_valid_pred_window)    # np.array (n, prediction_window)\n",
    "\n",
    "        y_train_pred = np.nanmean(y_train_pred_window_per_timestamp, axis=-1)    # np.array (n, )\n",
    "        y_valid_pred = np.nanmean(y_valid_pred_window_per_timestamp, axis=-1)    # np.array (n, )\n",
    "        \n",
    "        # Read the training data (CHANGE HERE)\n",
    "        X_train, X_valid, y_train, y_valid, y_train_dates, y_valid_dates = read_processed_data(Path(\"..\") / hyperparams['data_from'])    # torch.tensors\n",
    "\n",
    "        # Get the single target by taking the first value for each timestamp's target window\n",
    "        # ex. [y1, y2, y3, ..., y7], in this window, y1 is the target for that specific day\n",
    "        y_train_target, y_valid_target = y_train[:, 0].numpy(), y_valid[:, 0].numpy()    # np.array (n, )\n",
    "\n",
    "        # Calculate metrics\n",
    "        train_se, train_mse = calc_mse(y_train_target, y_train_pred)\n",
    "        train_ae, train_mae = calc_mae(y_train_target, y_train_pred)\n",
    "        train_ape, train_mape = calc_mape(y_train_target, y_train_pred)\n",
    "        _, train_rmse = calc_rmse(y_train_target, y_train_pred)\n",
    "        train_correct_direction, train_directional_acc = calc_directional_accuracy(y_train_target, y_train_pred)\n",
    "\n",
    "        valid_se, valid_mse = calc_mse(y_valid_target, y_valid_pred)\n",
    "        valid_ae, valid_mae = calc_mae(y_valid_target, y_valid_pred)\n",
    "        valid_ape, valid_mape = calc_mape(y_valid_target, y_valid_pred)\n",
    "        _, valid_rmse = calc_rmse(y_valid_target, y_valid_pred)\n",
    "        valid_correct_direction, valid_directional_acc = calc_directional_accuracy(y_valid_target, y_valid_pred)\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_dict = {\n",
    "            \"mse\": {\"train\": float(train_mse), \"valid\": float(valid_mse)},\n",
    "            \"mae\": {\"train\": float(train_mae), \"valid\": float(valid_mae)},\n",
    "            \"mape\": {\"train\": float(train_mape), \"valid\": float(valid_mape)},\n",
    "            \"rmse\": {\"train\": float(train_rmse), \"valid\": float(valid_rmse)},\n",
    "            \"directional_acc\": {\"train\": float(train_directional_acc), \"valid\": float(valid_directional_acc)},\n",
    "        }\n",
    "\n",
    "        metrics_file = results_save_path_ticker / \"metrics.json\"\n",
    "\n",
    "        with open(metrics_file, \"w\") as f:\n",
    "            json.dump(metrics_dict, f, indent=4)\n",
    "\n",
    "        # Produce plots\n",
    "        plots_save_path = results_save_path_ticker / \"plots\"\n",
    "\n",
    "        plot_interactive_predictions_with_slider(\n",
    "            y_train=y_train_target,\n",
    "            y_train_dates=y_train_dates,\n",
    "            y_valid=y_valid_target,\n",
    "            y_valid_dates=y_valid_dates,\n",
    "            predictions_dict=predictions_dict,\n",
    "            save_path=plots_save_path,\n",
    "            save_filename=\"predictions_with_slider.html\"\n",
    "        )\n",
    "\n",
    "        # Plot errors for each metric\n",
    "        plot_error(\n",
    "            individual_errors=np.concatenate([train_se, valid_se]),\n",
    "            dates=np.concatenate([y_train_dates, y_valid_dates]),\n",
    "            train_val_split_date=y_train_dates[-1],\n",
    "            title=\"Squared Error of the Predictions Through time\",\n",
    "            xlabel=\"Date\",\n",
    "            metric=\"Squared Error\",\n",
    "            figsize=(1200, 500),\n",
    "            save_path=plots_save_path\n",
    "        )\n",
    "\n",
    "        plot_error(\n",
    "            individual_errors=np.concatenate([train_ae, valid_ae]),\n",
    "            dates=np.concatenate([y_train_dates, y_valid_dates]),\n",
    "            train_val_split_date=y_train_dates[-1],\n",
    "            title=\"Absolute Error of the Predictions Through time\",\n",
    "            xlabel=\"Date\",\n",
    "            metric=\"Absolute Error\",\n",
    "            figsize=(1200, 500),\n",
    "            save_path=plots_save_path\n",
    "        )\n",
    "\n",
    "        plot_error(\n",
    "            individual_errors=np.concatenate([train_ape, valid_ape]),\n",
    "            dates=np.concatenate([y_train_dates, y_valid_dates]),\n",
    "            train_val_split_date=y_train_dates[-1],\n",
    "            title=\"Percentage Error of the Predictions Through time\",\n",
    "            xlabel=\"Date\",\n",
    "            metric=\"Percentage Error\",\n",
    "            figsize=(1200, 500),\n",
    "            save_path=plots_save_path\n",
    "        )\n",
    "\n",
    "        plot_directional_accuracy_heatmap(\n",
    "            directional_accuracy=np.concatenate([train_correct_direction, valid_correct_direction]),\n",
    "            dates=np.concatenate([y_train_dates, y_valid_dates]),\n",
    "            title=\"Directional Accuracy of Predictions Over Time\",\n",
    "            save_path=plots_save_path,\n",
    "            save_filename=None\n",
    "\n",
    "        )        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40077555-e48f-47db-a764-bfb34847c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] Plot saved to: predictions_with_slider.html\n",
      "[Saved] Plot saved to: results/2025_08_03_05_31_13/AAPL/plots/error_plot_squared_error.html\n",
      "[Saved] Plot saved to: results/2025_08_03_05_31_13/AAPL/plots/error_plot_absolute_error.html\n",
      "[Saved] Plot saved to: results/2025_08_03_05_31_13/AAPL/plots/error_plot_percentage_error.html\n",
      "[Saved] Plot saved to: results/2025_08_03_05_31_13/AAPL/plots/error_plot_directional_accuracy.html\n",
      "[Saved] Plot saved to: predictions_with_slider.html\n",
      "[Saved] Plot saved to: results/2025_08_03_05_31_13/GOOGL/plots/error_plot_squared_error.html\n",
      "[Saved] Plot saved to: results/2025_08_03_05_31_13/GOOGL/plots/error_plot_absolute_error.html\n",
      "[Saved] Plot saved to: results/2025_08_03_05_31_13/GOOGL/plots/error_plot_percentage_error.html\n",
      "[Saved] Plot saved to: results/2025_08_03_05_31_13/GOOGL/plots/error_plot_directional_accuracy.html\n"
     ]
    }
   ],
   "source": [
    "get_train_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634b1eb-519c-4611-b7aa-93ecfabc1a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
